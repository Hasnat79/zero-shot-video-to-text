{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "705"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "train_summary_id_to_caption_path = \"/home/grads/h/hasnat.md.abdullah/open_ended_activity_analysis/zero-shot-video-to-text/experiments/summary_study_activityNet/train exp/train_summary_id_to_caption.json\"\n",
    "with open(train_summary_id_to_caption_path,'r') as f:\n",
    "    train_summary_id_to_caption = json.load(f)\n",
    "\n",
    "len(train_summary_id_to_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE COUNT: 550\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "val_dir_path = \"/home/grads/h/hasnat.md.abdullah/open_ended_activity_analysis/zero-shot-video-to-text/data/ActivityNet_captions_dataset/training\"\n",
    "def find_file_path(directory, filename):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        if filename in files:\n",
    "            return os.path.join(root, filename)\n",
    "\n",
    "    return None\n",
    "\n",
    "count = 0\n",
    "for id in train_summary_id_to_caption.keys():\n",
    "    video_id = id[2:]\n",
    "    file_name = video_id+\".mp4\"\n",
    "    file_path = find_file_path(val_dir_path, file_name)\n",
    "\n",
    "    \n",
    "    if file_path:\n",
    "        # print(\"File found at:\", file_path)\n",
    "        train_summary_id_to_caption[id][\"path\"]=file_path\n",
    "        count+=1\n",
    "    # else:\n",
    "\n",
    "    #     print(f\"File not found: {id}\")\n",
    "    \n",
    "print(\"FILE COUNT:\",count)\n",
    "with open(\"/home/grads/h/hasnat.md.abdullah/open_ended_activity_analysis/zero-shot-video-to-text/experiments/summary_study_activityNet/train exp/train_summary_id_to_caption.json\",'w') as f:\n",
    "    json.dump(train_summary_id_to_caption,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging \n",
    "import json\n",
    "\n",
    "def load_json_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def merge_dicts(dict1, dict2):\n",
    "    merged_dict = {**dict1, **dict2}\n",
    "    return merged_dict\n",
    "\n",
    "def write_to_json_file(data, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from three JSON files\n",
    "    dict1 = load_json_file(\"/home/grads/h/hasnat.md.abdullah/open_ended_activity_analysis/zero-shot-video-to-text/experiments/summary_study_activityNet/train exp/output_train_summary_id_caption(0-353).json\")\n",
    "    dict2 = load_json_file(\"/home/grads/h/hasnat.md.abdullah/open_ended_activity_analysis/zero-shot-video-to-text/experiments/summary_study_activityNet/train exp/output_train_summary_id_caption(353-705).json\")\n",
    "       \n",
    "\n",
    "    # Merge the dictionaries\n",
    "    merged_dict = merge_dicts(dict1, dict2)\n",
    "\n",
    "    # Write the merged dictionary to a new JSON file\n",
    "    write_to_json_file(merged_dict, \"/home/grads/h/hasnat.md.abdullah/open_ended_activity_analysis/zero-shot-video-to-text/experiments/summary_study_activityNet/val_2 exp/output_val_2_summary_id_caption.json\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation of train set on zero-shot captioner. \n",
    "### bleu\n",
    "BLEU@1: 0.0526\n",
    "BLEU@2: 0.0000\n",
    "BLEU@3: 0.0000\n",
    "BLEU@4: 0.0000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705\n",
      "len(reference_captions) 550\n",
      "len(candidate_captions) 550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/h/hasnat.md.abdullah/open_ended_activity_analysis/oeaa/lib/python3.6/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/grads/h/hasnat.md.abdullah/open_ended_activity_analysis/oeaa/lib/python3.6/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/grads/h/hasnat.md.abdullah/open_ended_activity_analysis/oeaa/lib/python3.6/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cumulative BLEU scores:\n",
      "BLEU@1: 0.0526\n",
      "BLEU@2: 0.0000\n",
      "BLEU@3: 0.0000\n",
      "BLEU@4: 0.0000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "evaluating the generated summaries of 50 (least freq labels) videos\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
    "import statistics\n",
    "import string\n",
    "def load_json_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "def remove_punctuation(sentence):\n",
    "    # Remove punctuations from the sentence\n",
    "    no_punct = sentence.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Lowercase all the words\n",
    "    lowercase_sentence = no_punct.lower()\n",
    "\n",
    "    # stem words\n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "    sentence = \" \".join([stemmer.stem(word) for word in lowercase_sentence.split()])\n",
    "    return sentence\n",
    "\n",
    "\n",
    "output_val_2_summary_id_caption = load_json_file(\"/home/grads/h/hasnat.md.abdullah/open_ended_activity_analysis/zero-shot-video-to-text/experiments/summary_study_activityNet/train exp/output_train_summary_id_caption.json\")\n",
    "\n",
    "\n",
    "# bleu score calculation\n",
    "reference_captions = []\n",
    "candidate_captions = []\n",
    "print(len(output_val_2_summary_id_caption))\n",
    "for k,v in output_val_2_summary_id_caption.items():\n",
    "    if v['generated_summary']!=\"_\":\n",
    "        reference_captions.append(remove_punctuation(v['summary_cap']))\n",
    "        candidate_captions.append(remove_punctuation(v['generated_summary']))\n",
    "\n",
    "\n",
    "# Tokenize the captions\n",
    "reference_captions = [caption.split() for caption in reference_captions]\n",
    "candidate_captions = [caption.split() for caption in candidate_captions]\n",
    "\n",
    "print(\"len(reference_captions)\",len(reference_captions))\n",
    "print(\"len(candidate_captions)\",len(candidate_captions))\n",
    "# Calculate BLEU score\n",
    "cumulative_bleu_scores = []\n",
    "weight_list = [(1, 0, 0, 0),(0.5, 0.5, 0, 0),(0.33, 0.33, 0.33, 0),(0.25, 0.25, 0.25, 0.25)]\n",
    "for n in range(1, 5):\n",
    "    bleu_scores = [sentence_bleu(ref, cand, weights=weight_list[n-1]) for ref, cand in zip(reference_captions, candidate_captions)]\n",
    "    \n",
    "    # print(type(bleu_scores))\n",
    "\n",
    "    average_bleu_score = statistics.mean(bleu_scores)\n",
    "    cumulative_bleu_scores.append(average_bleu_score)\n",
    "\n",
    "# Print cumulative BLEU scores\n",
    "print(\"cumulative BLEU scores:\")\n",
    "for i, score in enumerate(cumulative_bleu_scores):\n",
    "    print(f\"BLEU@{i+1}: {score:.4f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metero for train\n",
    "\n",
    "*METEOR Score: 0.11133880097668851"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def remove_punctuation(sentence):\n",
    "    # Remove punctuations from the sentence\n",
    "    no_punct = sentence.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Lowercase all the words\n",
    "    lowercase_sentence = no_punct.lower()\n",
    "\n",
    "    # stem words\n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "    sentence = \" \".join([stemmer.stem(word) for word in lowercase_sentence.split()])\n",
    "    return sentence\n",
    "output_train_summary_id_caption = load_json_file(\"/home/grads/h/hasnat.md.abdullah/open_ended_activity_analysis/zero-shot-video-to-text/experiments/summary_study_activityNet/train exp/output_train_summary_id_caption.json\")\n",
    "\n",
    "reference_captions = []\n",
    "candidate_captions = []\n",
    "print(len(output_train_summary_id_caption))\n",
    "for k,v in output_train_summary_id_caption.items():\n",
    "    if v['generated_summary']!=\"_\":\n",
    "        reference_captions.append(remove_punctuation(v['summary_cap']))\n",
    "        candidate_captions.append(remove_punctuation(v['generated_summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METEOR Score: 0.11133880097668851\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "def calculate_meteor_score(ref_captions, cand_captions):\n",
    "    scores = []\n",
    "    for ref, cand in zip(ref_captions, cand_captions):\n",
    "        score = meteor_score([ref], cand)\n",
    "        scores.append(score)\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    return average_score\n",
    "\n",
    "# # Tokenize the captions\n",
    "reference_captions = [caption.split() for caption in reference_captions]\n",
    "candidate_captions = [caption.split() for caption in candidate_captions]\n",
    "\n",
    "meteor_score = calculate_meteor_score(reference_captions, candidate_captions)\n",
    "print(\"METEOR Score:\", meteor_score)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oeaa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
