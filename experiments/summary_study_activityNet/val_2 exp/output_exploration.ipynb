{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_json_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def merge_dicts(dict1, dict2, dict3):\n",
    "    merged_dict = {**dict1, **dict2, **dict3}\n",
    "    return merged_dict\n",
    "\n",
    "def write_to_json_file(data, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data from three JSON files\n",
    "    dict1 = load_json_file(\"/home/grads/h/hasnat.md.abdullah/open_ended_activity_analysis/zero-shot-video-to-text/experiments/summary_study_activityNet/val_2 exp/(0-55)output_val_2_summary_id_caption.json\")\n",
    "    dict2 = load_json_file(\"/home/grads/h/hasnat.md.abdullah/open_ended_activity_analysis/zero-shot-video-to-text/experiments/summary_study_activityNet/val_2 exp/(55-110)output_val_2_summary_id_caption.json\")\n",
    "    dict3 = load_json_file(\"/home/grads/h/hasnat.md.abdullah/open_ended_activity_analysis/zero-shot-video-to-text/experiments/summary_study_activityNet/val_2 exp/output_val_2_summary_id_caption.json\")\n",
    "\n",
    "    # Merge the dictionaries\n",
    "    merged_dict = merge_dicts(dict1, dict2, dict3)\n",
    "\n",
    "    # Write the merged dictionary to a new JSON file\n",
    "    write_to_json_file(merged_dict, \"/home/grads/h/hasnat.md.abdullah/open_ended_activity_analysis/zero-shot-video-to-text/experiments/summary_study_activityNet/val_2 exp/output_val_2_summary_id_caption.json\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_val_2_summary_id_caption = load_json_file(\"/home/grads/h/hasnat.md.abdullah/open_ended_activity_analysis/zero-shot-video-to-text/experiments/summary_study_activityNet/val_2 exp/output_val_2_summary_id_caption.json\")\n",
    "len(output_val_2_summary_id_caption)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation of val 2 set on zero-shot captioner. \n",
    "### bleu\n",
    "BLEU@1: 0.0605\n",
    "BLEU@2: 0.0000\n",
    "BLEU@3: 0.0000\n",
    "BLEU@4: 0.0000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434\n",
      "len(reference_captions) 331\n",
      "len(candidate_captions) 331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/h/hasnat.md.abdullah/open_ended_activity_analysis/oeaa/lib/python3.6/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/grads/h/hasnat.md.abdullah/open_ended_activity_analysis/oeaa/lib/python3.6/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/grads/h/hasnat.md.abdullah/open_ended_activity_analysis/oeaa/lib/python3.6/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cumulative BLEU scores:\n",
      "BLEU@1: 0.0605\n",
      "BLEU@2: 0.0000\n",
      "BLEU@3: 0.0000\n",
      "BLEU@4: 0.0000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "evaluating the generated summaries of 50 (least freq labels) videos\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
    "import statistics\n",
    "\n",
    "\n",
    "\n",
    "output_val_2_summary_id_caption = load_json_file(\"/home/grads/h/hasnat.md.abdullah/open_ended_activity_analysis/zero-shot-video-to-text/experiments/summary_study_activityNet/val_2 exp/output_val_2_summary_id_caption.json\")\n",
    "\n",
    "\n",
    "# bleu score calculation\n",
    "reference_captions = []\n",
    "candidate_captions = []\n",
    "print(len(output_val_2_summary_id_caption))\n",
    "for k,v in output_val_2_summary_id_caption.items():\n",
    "    if v['generated_summary']!=\"_\":\n",
    "        reference_captions.append( v['summary_cap'])\n",
    "        candidate_captions.append(v['generated_summary'])\n",
    "\n",
    "\n",
    "# Tokenize the captions\n",
    "reference_captions = [caption.split() for caption in reference_captions]\n",
    "candidate_captions = [caption.split() for caption in candidate_captions]\n",
    "\n",
    "print(\"len(reference_captions)\",len(reference_captions))\n",
    "print(\"len(candidate_captions)\",len(candidate_captions))\n",
    "# Calculate BLEU score\n",
    "cumulative_bleu_scores = []\n",
    "weight_list = [(1, 0, 0, 0),(0.5, 0.5, 0, 0),(0.33, 0.33, 0.33, 0),(0.25, 0.25, 0.25, 0.25)]\n",
    "for n in range(1, 5):\n",
    "    bleu_scores = [sentence_bleu(ref, cand, weights=weight_list[n-1]) for ref, cand in zip(reference_captions, candidate_captions)]\n",
    "    \n",
    "    # print(type(bleu_scores))\n",
    "\n",
    "    average_bleu_score = statistics.mean(bleu_scores)\n",
    "    cumulative_bleu_scores.append(average_bleu_score)\n",
    "\n",
    "# Print cumulative BLEU scores\n",
    "print(\"cumulative BLEU scores:\")\n",
    "for i, score in enumerate(cumulative_bleu_scores):\n",
    "    print(f\"BLEU@{i+1}: {score:.4f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate meteor score of val 2\n",
    "METEOR Score: 0.09812680535507115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434\n"
     ]
    }
   ],
   "source": [
    "output_val_2_summary_id_caption = load_json_file(\"/home/grads/h/hasnat.md.abdullah/open_ended_activity_analysis/zero-shot-video-to-text/experiments/summary_study_activityNet/val_2 exp/output_val_2_summary_id_caption.json\")\n",
    "\n",
    "\n",
    "reference_captions = []\n",
    "candidate_captions = []\n",
    "print(len(output_val_2_summary_id_caption))\n",
    "for k,v in output_val_2_summary_id_caption.items():\n",
    "    if v['generated_summary']!=\"_\":\n",
    "        reference_captions.append(v['summary_cap'])\n",
    "        candidate_captions.append(v['generated_summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METEOR Score: 0.09812680535507115\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "def calculate_meteor_score(ref_captions, cand_captions):\n",
    "    scores = []\n",
    "    for ref, cand in zip(ref_captions, cand_captions):\n",
    "        score = meteor_score([ref], cand)\n",
    "        scores.append(score)\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    return average_score\n",
    "\n",
    "# # Tokenize the captions\n",
    "reference_captions = [caption.split() for caption in reference_captions]\n",
    "candidate_captions = [caption.split() for caption in candidate_captions]\n",
    "\n",
    "meteor_score = calculate_meteor_score(reference_captions, candidate_captions)\n",
    "print(\"METEOR Score:\", meteor_score)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oeaa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
